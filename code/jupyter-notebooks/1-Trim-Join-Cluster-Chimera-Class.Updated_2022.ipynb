{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First pipeline steps\n",
    "## Pipline to clean, join, filter, and check sequences before OTU picking/clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (run these each time you restart notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific variables that should not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REF=/home/sam/data/databases/silva\n",
      "env: TRIMMOMATIC=/home/sam/programs/Trimmomatic-0.39/trimmomatic-0.39.jar\n"
     ]
    }
   ],
   "source": [
    "# Path to directory containing reference reads/seqs/taxonomy files\n",
    "%env REF=\n",
    "\n",
    "# Path to Trimmomatic\n",
    "%env TRIMMOMATIC=\n",
    "\n",
    "import os\n",
    "ref = os.getenv(\"REF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up run specific variables\n",
    "\n",
    "Replace all `<text>` (including the `<>`) below with expected paths/files/values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLUSTER_PER=99\n",
      "env: MYREF=/home/sam/data/databases/silva/silva_132_97_16S.qza\n",
      "env: REF_SEQS=/home/sam/data/databases/silva/Silva-ref-seqs.qza\n",
      "env: MYTAXA=/home/sam/data/databases/silva/Silva_taxonomy.qza\n",
      "env: THREADS=8\n"
     ]
    }
   ],
   "source": [
    "# Set full path to output directory\n",
    "base = \"\"\n",
    "\n",
    "# Add path to directory containing FastQ files for analysis\n",
    "%env RAW=$ref/<FastQ directory>\n",
    "\n",
    "# Specific to clustering\n",
    "%env CLUSTER_PER=<97>\n",
    "%env MYREF=$ref/<Silva ref QZA>\n",
    "\n",
    "# Reference sequences and taxa QZAs\n",
    "%env REF_SEQS=$ref/<Silva reference seqs QZA>\n",
    "%env MYTAXA=$ref/<Silva taxonomy QZA>\n",
    "\n",
    "# CPU threads\n",
    "%env THREADS=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'base' is the main folder that will contain the analysis\n",
    "\n",
    "'RAW' will contain the original sequencing files (fastq.gz)\n",
    "\n",
    "'TRIM_OUT' contains the trimmed fastq files\n",
    "\n",
    "'PANDA_OUT' contains the joined/merged fasta files\n",
    "\n",
    "'FILTER_OUT' contains the filtered fasta files with renamed sequences\n",
    "\n",
    "'CONVERT_OUT' contains the input for QIIME 2\n",
    "\n",
    "'CHIMERA_OUT' contains the chimera checked sequences\n",
    "\n",
    "'CLUSTER_OUT' contains the clustered OTU output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent\n",
      "env: RAW=/home/sam/data/databases/silva/MiSeq_files_for_Gannet\n",
      "env: TRIM_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/trimmed\n",
      "env: PANDA_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/joined\n",
      "env: FILTER_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/filtered\n",
      "env: CONVERT_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/converted\n",
      "env: CHIMERA_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/chimera_checked\n",
      "env: CLUSTER_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered\n",
      "env: CLASSIFY_OUT=/home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/classified\n",
      "env: REFSEQ=/home/sam/data/databases/silva/\n"
     ]
    }
   ],
   "source": [
    "%env BASE=$base\n",
    "%env TRIM_OUT=$base/trimmed\n",
    "%env PANDA_OUT=$base/joined\n",
    "%env FILTER_OUT=$base/filtered\n",
    "%env CONVERT_OUT=$base/converted\n",
    "%env CHIMERA_OUT=$base/chimera_checked\n",
    "%env CLUSTER_OUT=$base/clustered\n",
    "%env CLASSIFY_OUT=$base/classified\n",
    "\n",
    "\n",
    "# Specific to classifying\n",
    "%env REFSEQ=$ref/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310_S11_L001\n",
      "311_S12_L001\n",
      "312_S13_L001\n",
      "313_S14_L001\n",
      "314_S15_L001\n",
      "315_S16_L001\n",
      "316_S17_L001\n",
      "317_S18_L001\n",
      "318_S19_L001\n",
      "319_S20_L001\n",
      "320_S21_L001\n",
      "Neg_S92_L001\n",
      "Pos_S88_L001\n",
      "\n",
      "Sample Count = 13\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir --parents ${BASE}\n",
    "\n",
    "if [[ -e ${BASE}/sample_ids.txt ]]; then\n",
    "    rm ${BASE}/sample_ids.txt\n",
    "fi\n",
    "\n",
    "for file in ${RAW}/*R1*\n",
    "do\n",
    "    NAME=$(echo ${file} | awk -F \"/\" '{print $NF}' | awk -F \".R1\" '{print $1}')\n",
    "    echo ${NAME}\n",
    "    echo ${NAME} >> ${BASE}/sample_ids.txt\n",
    "done\n",
    "\n",
    "SAMPLE_COUNT=$(wc ${BASE}/sample_ids.txt | awk '{print $1}')\n",
    "echo -e \"\\nSample Count = ${SAMPLE_COUNT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Missing adapter trimming FastA step - just for testing pipeline with new DBs\n",
    "\n",
    "## Trimming - Trimmomatic\n",
    "Trimmomatic Steps\n",
    "1. Remove adapters\n",
    "2. Remove leading/trailing low quality bases (quality score if 3 or lower, remove sequence)\n",
    "3. Sliding window quality trimming (window of size 8 with average quality score of 10, remove if below)\n",
    "4. Removing short reads (if length < 100)\n",
    "\n",
    "\n",
    "Output:\n",
    "- NAME.trimmed.paired.R1 : Sample trimmed paired R1 reads\n",
    "- NAME.trimmed.paired.R2 : Sample trimmed paired R2 reads\n",
    "- NAME.trimmed.unpaired.R1 : Sample trimmed broken R1 reads\n",
    "- NAME.trimmed.unpaired.R2 : Sample trimmed broken R2 reads\n",
    "- NAME.trimmomatic.log : Per sequence trimming information\n",
    "- NAME.trimmomatic.stats.txt : Trimming stats for sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${TRIM_OUT} ]; then\n",
    "    mkdir ${TRIM_OUT}\n",
    "fi\n",
    "\n",
    "for NAME in $(cat ${BASE}/sample_ids.txt)\n",
    "do\n",
    "    java -jar ${TRIMMOMATIC} \\\n",
    "        PE -phred33 \\\n",
    "        -threads ${THREADS} \\\n",
    "        -trimlog ${TRIM_OUT}/${NAME}.trimmomatic.log \\\n",
    "        ${RAW}/${NAME}_R1_001.fastq.gz \\\n",
    "        ${RAW}/${NAME}_R2_001.fastq.gz \\\n",
    "        ${TRIM_OUT}/${NAME}.trimmed.paired.R1.fq \\\n",
    "        ${TRIM_OUT}/${NAME}.trimmed.unpaired.R1.fq \\\n",
    "        ${TRIM_OUT}/${NAME}.trimmed.paired.R2.fq \\\n",
    "        ${TRIM_OUT}/${NAME}.trimmed.unpaired.R2.fq \\\n",
    "        ILLUMINACLIP:/home/sam/programs/Trimmomatic-0.39/adapters/NexteraPE-PE.fa:2:30:10 \\\n",
    "        LEADING:3 \\\n",
    "        TRAILING:3 \\\n",
    "        SLIDINGWINDOW:8:10 \\\n",
    "        MINLEN:100 \\\n",
    "        > ${TRIM_OUT}/${NAME}.trimmomatic.stats.txt 2>&1\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the samples that passed trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310_S11_L001\n",
      "311_S12_L001\n",
      "312_S13_L001\n",
      "313_S14_L001\n",
      "314_S15_L001\n",
      "315_S16_L001\n",
      "316_S17_L001\n",
      "317_S18_L001\n",
      "318_S19_L001\n",
      "319_S20_L001\n",
      "320_S21_L001\n",
      "Neg_S92_L001\n",
      "Pos_S88_L001\n",
      "\n",
      "Sample Count = 13\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Generate list of sample ids that passed trimming\n",
    "if [ -f ${BASE}/sample_ids.pass_trimmed.txt ]; then\n",
    "    rm ${BASE}/sample_ids.pass_trimmed.txt\n",
    "fi\n",
    "\n",
    "for file in $(ls -1 ${TRIM_OUT}/*trimmed.paired.R1.fq)\n",
    "do\n",
    "    NAME=$(echo ${file} | awk -F \"/\" '{print $NF}' | awk -F \".trimmed\" '{print $1}')\n",
    "    echo ${NAME}\n",
    "    echo ${NAME} >> ${BASE}/sample_ids.pass_trimmed.txt\n",
    "done\n",
    "\n",
    "SAMPLE_COUNT=$(wc ${BASE}/sample_ids.pass_trimmed.txt | awk '{print $1}')\n",
    "echo -e \"\\nSample Count = ${SAMPLE_COUNT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining - pandaseq\n",
    "\n",
    "Output:\n",
    "- NAME.joined.fa : Sample joined sequence fasta file\n",
    "- NAME.joined.lengths.txt : Lengths of the sequences from the fasta file\n",
    "- NAME.pandaseq.log : Log file from pandaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${PANDA_OUT} ]; then\n",
    "    mkdir ${PANDA_OUT}\n",
    "fi\n",
    "\n",
    "for NAME in $(cat ${BASE}/sample_ids.pass_trimmed.txt)\n",
    "do\n",
    "    pandaseq \\\n",
    "        -T 8 \\\n",
    "        -g ${PANDA_OUT}/${NAME}.pandaseq.log \\\n",
    "        -f ${TRIM_OUT}/${NAME}.trimmed.paired.R1.fq \\\n",
    "        -r ${TRIM_OUT}/${NAME}.trimmed.paired.R2.fq \\\n",
    "        -w ${PANDA_OUT}/${NAME}.joined.fa\n",
    "\n",
    "    ./seq_dist.pl \\\n",
    "        ${PANDA_OUT}/${NAME}.joined.fa \\\n",
    "        > ${PANDA_OUT}/${NAME}.joined.lengths.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310_S11_L001\n",
      "311_S12_L001\n",
      "312_S13_L001\n",
      "313_S14_L001\n",
      "314_S15_L001\n",
      "315_S16_L001\n",
      "316_S17_L001\n",
      "317_S18_L001\n",
      "318_S19_L001\n",
      "319_S20_L001\n",
      "320_S21_L001\n",
      "Neg_S92_L001\n",
      "Pos_S88_L001\n",
      "\n",
      "Sample Count = 13\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Generate list of samples that passed the joining step\n",
    "if [ -f ${BASE}/sample_ids.pass_joined.txt ]; then\n",
    "    rm ${BASE}/sample_ids.pass_joined.txt\n",
    "fi\n",
    "\n",
    "for file in $(ls -1 ${PANDA_OUT}/*joined.fa)\n",
    "do\n",
    "    NAME=$(echo ${file} | awk -F \"/\" '{print $NF}' | awk -F \".joined\" '{print $1}')\n",
    "    echo ${NAME}\n",
    "    echo ${NAME} >> ${BASE}/sample_ids.pass_joined.txt\n",
    "done\n",
    "\n",
    "SAMPLE_COUNT=$(wc ${BASE}/sample_ids.pass_joined.txt | awk '{print $1}')\n",
    "echo -e \"\\nSample Count = ${SAMPLE_COUNT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats for each sample after joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              X1  X2  X3       X4  X5  X6\n",
      "310_S11_L001 100 443 464 451.2833 465 595\n",
      "311_S12_L001 100 443 460 454.1084 465 599\n",
      "312_S13_L001 100 440 460 428.3542 465 599\n",
      "313_S14_L001 100 459 465 455.9755 465 598\n",
      "314_S15_L001 100 460 465 453.0552 465 599\n",
      "315_S16_L001 100 440 464 435.2126 465 599\n",
      "316_S17_L001 100 442 465 441.9699 465 597\n",
      "317_S18_L001 100 459 464 441.4208 465 600\n",
      "318_S19_L001 100 387 440 407.2018 465 599\n",
      "319_S20_L001 100 440 464 451.2084 465 599\n",
      "320_S21_L001 100 440 465 453.2890 465 598\n",
      "Neg_S92_L001 100 464 465 460.5435 465 580\n",
      "Pos_S88_L001 101 460 465 460.1400 465 595\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Run the R script to generate the stats\n",
    "./seq_stats.R ${PANDA_OUT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and renaming sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering\n",
    "- Removing if\n",
    "  - 7 or more N's\n",
    "  - Homopolymers greater then 7 in length\n",
    "  - Sequence length less than 400\n",
    "  \n",
    "  \n",
    "- Need to rename the sequences to contain the sample ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Setup the filter output folder\n",
    "if [ ! -d ${FILTER_OUT} ]; then\n",
    "    mkdir ${FILTER_OUT}\n",
    "fi\n",
    "\n",
    "# Loop through the samples and filter the fasta files\n",
    "for NAME in $(cat ${BASE}/sample_ids.pass_joined.txt)\n",
    "do\n",
    "    ./seq_rename_and_filter.pl \\\n",
    "        ${PANDA_OUT}/${NAME}.joined.fa \\\n",
    "        ${NAME} \\\n",
    "        7 7 400 \\\n",
    "        > ${FILTER_OUT}/${NAME}.filtered.fa\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310_S11_L001\n",
      "311_S12_L001\n",
      "312_S13_L001\n",
      "313_S14_L001\n",
      "314_S15_L001\n",
      "315_S16_L001\n",
      "316_S17_L001\n",
      "317_S18_L001\n",
      "318_S19_L001\n",
      "319_S20_L001\n",
      "320_S21_L001\n",
      "Neg_S92_L001\n",
      "Pos_S88_L001\n",
      "\n",
      "Sample Count = 13\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Generate list of samples that passed the filtering step\n",
    "if [ -f ${BASE}/sample_ids.pass_filtered.txt ]; then\n",
    "    rm ${BASE}/sample_ids.pass_filtered.txt\n",
    "fi\n",
    "\n",
    "for file in $(ls -1 ${FILTER_OUT}/*.filtered.fa)\n",
    "do\n",
    "    NAME=$(echo ${file} | awk -F \"/\" '{print $NF}' | awk -F \".filtered\" '{print $1}')\n",
    "    echo ${NAME}\n",
    "    echo ${NAME} >> ${BASE}/sample_ids.pass_filtered.txt\n",
    "done\n",
    "\n",
    "SAMPLE_COUNT=$(wc ${BASE}/sample_ids.pass_filtered.txt | awk '{print $1}')\n",
    "echo -e \"\\nSample Count = ${SAMPLE_COUNT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of QIIME 2 Stuff\n",
    "## Import fasta file into QIIME2 as a qza file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/converted/all.sequences.filtered.fa as QIIME1DemuxDirFmt to /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/converted/all.sequences.filtered.qza\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${CONVERT_OUT} ]; then\n",
    "    mkdir ${CONVERT_OUT}\n",
    "fi\n",
    "\n",
    "# Merge the filtered fasta files into a single file for import\n",
    "cat ${FILTER_OUT}/*filtered.fa >> ${CONVERT_OUT}/all.sequences.filtered.fa\n",
    "\n",
    "qiime \\\n",
    "    tools import \\\n",
    "    --input-path ${CONVERT_OUT}/all.sequences.filtered.fa \\\n",
    "    --output-path ${CONVERT_OUT}/all.sequences.filtered.qza \\\n",
    "    --type 'SampleData[Sequences]' \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dereplicate the qza file to generate the frequency table qza file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FeatureTable[Frequency] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/converted/rep-seqs.table.qza\n",
      "Saved FeatureData[Sequence] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/converted/rep-seqs.qza\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "qiime \\\n",
    "    vsearch dereplicate-sequences \\\n",
    "    --i-sequences ${CONVERT_OUT}/all.sequences.filtered.qza \\\n",
    "    --o-dereplicated-table ${CONVERT_OUT}/rep-seqs.table.qza \\\n",
    "    --o-dereplicated-sequences ${CONVERT_OUT}/rep-seqs.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reference file for clustering\n",
    "## This is for a 97% clustered file from Silva_132 release\n",
    "## SKIP THIS STEP IF THE REFERENCE FILE ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was a problem importing /home/sam/data/databases/silva/raw/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta:\n",
      "\n",
      "  /home/sam/data/databases/silva/raw/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta is not a(n) DNAFASTAFormat file:\n",
      "\n",
      "  Multiple consecutive descriptions starting on line 563312\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nqiime tools import \\\\\\n    --input-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta \\\\\\n    --output-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.qza \\\\\\n    --type FeatureData[Sequence]\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mqiime tools import \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --input-path $\u001b[39;49m\u001b[38;5;132;43;01m{RAW}\u001b[39;49;00m\u001b[38;5;124;43m/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --output-path $\u001b[39;49m\u001b[38;5;132;43;01m{RAW}\u001b[39;49;00m\u001b[38;5;124;43m/SILVA_138.1_SSURef_NR99_tax_silva.DNA.qza \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --type FeatureData[Sequence]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programs/miniconda3/envs/qiime2-2022.2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2347\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2346\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2347\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/programs/miniconda3/envs/qiime2-2022.2/lib/python3.8/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programs/miniconda3/envs/qiime2-2022.2/lib/python3.8/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nqiime tools import \\\\\\n    --input-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta \\\\\\n    --output-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.qza \\\\\\n    --type FeatureData[Sequence]\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "qiime tools import \\\n",
    "    --input-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.fasta \\\n",
    "    --output-path ${RAW}/SILVA_138.1_SSURef_NR99_tax_silva.DNA.qza \\\n",
    "    --type FeatureData[Sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU Clustering: either use open reference or closed reference.\n",
    "## Both options are listed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with open reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FeatureTable[Frequency] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/table-or-99.qza\n",
      "Saved FeatureData[Sequence] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/rep-seqs-or-99.qza\n",
      "Saved FeatureData[Sequence] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/new-ref-seqs-or-99.qza\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${CLUSTER_OUT} ]; then\n",
    "    mkdir ${CLUSTER_OUT}\n",
    "fi\n",
    "\n",
    "qiime \\\n",
    "    vsearch cluster-features-open-reference \\\n",
    "    --i-table ${CONVERT_OUT}/rep-seqs.table.qza \\\n",
    "    --i-sequences ${CONVERT_OUT}/rep-seqs.qza \\\n",
    "    --i-reference-sequences ${MYREF} \\\n",
    "    --p-perc-identity 0.${CLUSTER_PER} \\\n",
    "    --o-clustered-table ${CLUSTER_OUT}/table-or-${CLUSTER_PER}.qza \\\n",
    "    --o-clustered-sequences ${CLUSTER_OUT}/rep-seqs-or-${CLUSTER_PER}.qza \\\n",
    "    --o-new-reference-sequences ${CLUSTER_OUT}/new-ref-seqs-or-${CLUSTER_PER}.qza \\\n",
    "    --p-threads 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with closed reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FeatureTable[Frequency] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/table-cr-99.qza\n",
      "Saved FeatureData[Sequence] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/rep-seqs-cr-99.qza\n",
      "Saved FeatureData[Sequence] to: /home/sam/analyses/20221118-rhodes-marine_mammals-16s-silva-original-99-percent/clustered/unmatched-ref-seqs-cr-99.qza\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${CLUSTER_OUT} ]; then\n",
    "    mkdir ${CLUSTER_OUT}\n",
    "fi\n",
    "\n",
    "qiime \\\n",
    "    vsearch cluster-features-closed-reference \\\n",
    "    --i-table ${CONVERT_OUT}/rep-seqs.table.qza \\\n",
    "    --i-sequences ${CONVERT_OUT}/rep-seqs.qza \\\n",
    "    --i-reference-sequences ${MYREF} \\\n",
    "    --p-perc-identity 0.${CLUSTER_PER} \\\n",
    "    --o-clustered-table ${CLUSTER_OUT}/table-cr-${CLUSTER_PER}.qza \\\n",
    "    --o-clustered-sequences ${CLUSTER_OUT}/rep-seqs-cr-${CLUSTER_PER}.qza \\\n",
    "    --o-unmatched-sequences ${CLUSTER_OUT}/unmatched-ref-seqs-cr-${CLUSTER_PER}.qza \\\n",
    "    --p-threads 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chimera Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${CHIMERA_OUT} ]; then\n",
    "    mkdir ${CHIMERA_OUT}\n",
    "fi\n",
    "\n",
    "qiime \\\n",
    "    vsearch uchime-denovo \\\n",
    "    --i-table ${CLUSTER_OUT}/table-or-${CLUSTER_PER}.qza \\\n",
    "    --i-sequences ${CLUSTER_OUT}/rep-seqs-or-${CLUSTER_PER}.qza \\\n",
    "    --o-chimeras ${CHIMERA_OUT}/chimeras.qza \\\n",
    "    --o-nonchimeras ${CHIMERA_OUT}/nonchimeras.qza \\\n",
    "    --o-stats ${CHIMERA_OUT}/chimera-check-stats.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the non-chimeric sequences to exlude chimeras & borderline sequences from the clustered table & sequence files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "qiime \\\n",
    "    feature-table filter-features \\\n",
    "    --i-table ${CLUSTER_OUT}/table-or-${CLUSTER_PER}.qza \\\n",
    "    --m-metadata-file ${CHIMERA_OUT}/nonchimeras.qza \\\n",
    "    --o-filtered-table ${CHIMERA_OUT}/table-nonchimeric-wo-borderline.qza\n",
    "\n",
    "qiime \\\n",
    "    feature-table filter-seqs \\\n",
    "    --i-data ${CLUSTER_OUT}/rep-seqs-or-${CLUSTER_PER}.qza \\\n",
    "    --m-metadata-file ${CHIMERA_OUT}/nonchimeras.qza \\\n",
    "    --o-filtered-data ${CHIMERA_OUT}/rep-seqs-nonchimeric-wo-borderline.qza\n",
    "\n",
    "qiime \\\n",
    "    feature-table summarize \\\n",
    "    --i-table ${CHIMERA_OUT}/table-nonchimeric-wo-borderline.qza \\\n",
    "    --o-visualization ${CHIMERA_OUT}/table-nonchimeric-wo-borderline.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine chimera filtering statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "qiime metadata tabulate \\\n",
    "  --m-input-file ${CHIMERA_OUT}/chimera-check-stats.qza \\\n",
    "  --o-visualization ${CHIMERA_OUT}/chimera-check-stats.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify OTUs with VSEARCH consensus classifier using reference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d ${CLASSIFY_OUT} ]; then\n",
    "    mkdir ${CLASSIFY_OUT}\n",
    "fi\n",
    "\n",
    "qiime feature-classifier classify-consensus-vsearch \\\n",
    "    --i-query ${CHIMERA_OUT}/nonchimeras.qza \\\n",
    "    --i-reference-reads ${MYREF} \\\n",
    "    --i-reference-taxonomy ${REFSEQ}/${MYTAXA} \\\n",
    "    --p-maxaccepts 10 \\\n",
    "    --p-perc-identity 0.8 \\\n",
    "    --p-strand \"both\" \\\n",
    "    --p-min-consensus 0.51 \\\n",
    "    --p-threads ${THREADS} \\\n",
    "    --o-classification ${CLASSIFY_OUT}/rep-seqs-classified-by-Silva.qza \\\n",
    "    --output-dir ${CLASSIFY_OUT}/rep-seqs-unspecified-by-Silva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
